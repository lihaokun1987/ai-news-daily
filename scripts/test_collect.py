#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¦»çº¿æµ‹è¯•è„šæœ¬ - æµ‹è¯•æ–°é—»æŠ“å–åŠŸèƒ½ï¼ˆV2ï¼‰
"""

import sys
import os

# ç¡®ä¿å¯ä»¥å¯¼å…¥ä¸»è„šæœ¬
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from collect_news import AINewsCollector
from datetime import datetime

def test_collect():
    """æµ‹è¯•æ–°é—»æŠ“å–åŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ§ª AIæ–°é—»æŠ“å–åŠŸèƒ½ç¦»çº¿æµ‹è¯• V2")
    print("=" * 60)
    print()
    
    collector = AINewsCollector()
    
    print(f"ğŸ“… ç›®æ ‡æ—¥æœŸ: {collector.yesterday}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {collector.output_dir}")
    print()
    
    # åˆ†åˆ«æµ‹è¯•å„ä¸ªæ•°æ®æº
    print("-" * 60)
    print("1ï¸âƒ£ æµ‹è¯•ç½‘ç»œæœç´¢ï¼ˆBing RSSï¼‰...")
    print("-" * 60)
    web_queries = ['AI breakthrough', 'ChatGPT OpenAI', 'Claude Anthropic']
    web_results = collector.search_news_from_web(web_queries)
    print(f"   âœ… è·å– {len(web_results)} æ¡æ–°é—»")
    if web_results:
        print(f"   ğŸ“° ç¤ºä¾‹: {web_results[0].get('title', '')[:60]}...")
    print()
    
    print("-" * 60)
    print("2ï¸âƒ£ æµ‹è¯•Twitter/XæŠ“å–...")
    print("-" * 60)
    twitter_keywords = ['AI', 'ChatGPT', 'LLM']
    twitter_results = collector.search_from_twitter(twitter_keywords)
    print(f"   âœ… è·å– {len(twitter_results)} æ¡æ¨æ–‡")
    if twitter_results:
        sample = twitter_results[0]
        author = sample.get('author', {})
        username = author.get('username', 'unknown') if isinstance(author, dict) else 'unknown'
        print(f"   ğŸ¦ ç¤ºä¾‹: @{username}: {sample.get('text', '')[:50]}...")
    print()
    
    print("-" * 60)
    print("3ï¸âƒ£ æµ‹è¯•RedditæŠ“å–...")
    print("-" * 60)
    reddit_results = collector.search_from_reddit()
    print(f"   âœ… è·å– {len(reddit_results)} æ¡å¸–å­")
    if reddit_results:
        print(f"   ğŸ“± ç¤ºä¾‹: [{reddit_results[0].get('source', '')}] {reddit_results[0].get('title', '')[:50]}...")
    print()
    
    print("-" * 60)
    print("4ï¸âƒ£ æµ‹è¯•ä¸­æ–‡æ–°é—»æºæŠ“å–...")
    print("-" * 60)
    chinese_results = collector.search_from_chinese_sources()
    print(f"   âœ… è·å– {len(chinese_results)} æ¡æ–°é—»")
    if chinese_results:
        print(f"   ğŸ“ ç¤ºä¾‹: [{chinese_results[0].get('source', '')}] {chinese_results[0].get('title', '')[:40]}...")
    print()
    
    print("-" * 60)
    print("5ï¸âƒ£ æµ‹è¯•å®˜æ–¹åšå®¢æŠ“å–...")
    print("-" * 60)
    websites = [
        'https://www.anthropic.com/news',
        'https://openai.com/blog',
    ]
    blog_results = collector.extract_from_websites(websites)
    print(f"   âœ… è·å– {len(blog_results)} æ¡å†…å®¹")
    if blog_results:
        print(f"   ğŸ“ ç¤ºä¾‹: {blog_results[0].get('title', '')[:60]}...")
    print()
    
    # æ±‡æ€»å¹¶ç”ŸæˆæŠ¥å‘Š
    print("=" * 60)
    print("ğŸ“Š æ±‡æ€»æµ‹è¯•ç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š...")
    print("=" * 60)
    
    # æ‰‹åŠ¨æ·»åŠ ç»“æœåˆ°collector
    for item in web_results:
        if isinstance(item, dict) and 'title' in item:
            if collector.is_valid_url(item.get('url', '')):
                score = collector.calculate_score(item)
                collector.news_items.append({
                    **item,
                    'score': score,
                    'collection_time': datetime.now().isoformat()
                })
    
    for tweet in twitter_results:
        if isinstance(tweet, dict):
            tweet_text = tweet.get('text', '')[:200]
            author = tweet.get('author', {})
            username = author.get('username', 'unknown') if isinstance(author, dict) else 'unknown'
            tweet_id = tweet.get('id', '')
            
            score = collector.calculate_score({
                'title': tweet_text[:100],
                'source': f"Twitter @{username}"
            })
            
            collector.news_items.append({
                'title': tweet_text,
                'source': f"Twitter @{username}",
                'url': f"https://twitter.com/{username}/status/{tweet_id}" if tweet_id else f"https://twitter.com/{username}",
                'publish_time': tweet.get('posted', collector.yesterday),
                'engagement': tweet.get('engagement', {}),
                'score': score,
                'collection_time': datetime.now().isoformat()
            })
    
    for post in reddit_results:
        if isinstance(post, dict) and 'title' in post:
            score = collector.calculate_score(post)
            collector.news_items.append({
                **post,
                'score': score,
                'collection_time': datetime.now().isoformat()
            })
    
    for item in chinese_results:
        if isinstance(item, dict) and 'title' in item:
            if collector.is_valid_url(item.get('url', '')):
                score = collector.calculate_score(item)
                collector.news_items.append({
                    **item,
                    'score': score,
                    'collection_time': datetime.now().isoformat()
                })
    
    for result in blog_results:
        if isinstance(result, dict) and 'title' in result:
            score = collector.calculate_score(result)
            collector.news_items.append({
                **result,
                'score': score,
                'collection_time': datetime.now().isoformat()
            })
    
    print(f"\nğŸ“ˆ æ€»è®¡æ”¶é›†: {len(collector.news_items)} æ¡æ–°é—»")
    print(f"   - ç½‘ç»œæœç´¢: {len(web_results)} æ¡")
    print(f"   - Twitter: {len(twitter_results)} æ¡")
    print(f"   - Reddit: {len(reddit_results)} æ¡")
    print(f"   - ä¸­æ–‡æ–°é—»æº: {len(chinese_results)} æ¡")
    print(f"   - å®˜æ–¹åšå®¢: {len(blog_results)} æ¡")
    
    # ä¿å­˜æŠ¥å‘Š
    if collector.news_items:
        md_path, json_path, total_count = collector.save_reports()
        
        print()
        print("=" * 60)
        print("âœ… æµ‹è¯•å®Œæˆï¼")
        print("=" * 60)
        print(f"ğŸ“„ MarkdownæŠ¥å‘Š: {md_path}")
        print(f"ğŸ“Š JSONæ–‡ä»¶: {json_path}")
        print(f"ğŸ“° æœ‰æ•ˆæ–°é—»æ•°: {total_count}")
        
        # æ˜¾ç¤ºTop 5æ–°é—»
        print()
        print("-" * 60)
        print("ğŸ† Top 5 æ–°é—»é¢„è§ˆ:")
        print("-" * 60)
        sorted_news = collector.sort_and_filter(5)
        for i, news in enumerate(sorted_news, 1):
            score = news.get('score', {}).get('total_score', 0)
            source = news.get('source', 'æœªçŸ¥')
            title = news.get('title', 'æ— æ ‡é¢˜')[:50]
            print(f"  {i}. [{score}/10] [{source}] {title}...")
    else:
        print()
        print("âš ï¸ æœªèƒ½æ”¶é›†åˆ°ä»»ä½•æ–°é—»ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")


if __name__ == '__main__':
    test_collect()
